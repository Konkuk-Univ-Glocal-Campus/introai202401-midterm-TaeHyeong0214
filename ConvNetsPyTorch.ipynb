{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks\n",
    "\n",
    "In this unit we will learn about **Convolutional Neural Networks (CNNs)**, which are specifically designed for computer vision.\n",
    "\n",
    "Computer vision is different from generic classification, because when we are trying to find a certain object in the picture, we are scanning the image looking for some specific **patterns** and their combinations. For example, when looking for a cat, we first may look for horizontal lines, which can form whiskers, and then certain combination of whiskers can tell us that it is actually a picture of a cat. Relative position and presence of certain patterns is important, and not their exact position on the image. \n",
    "\n",
    "To extract patterns, we will use the notion of **convolutional filters**. But first, let us load all dependencies and functions that we have defined in the previous units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/computer-vision-pytorch/pytorchcv.py\n",
    "%pip install torchvision\n",
    "%pip install torchinfo\n",
    "%pip install pytorchcv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import pytorchcv\n",
    "\n",
    "from pytorchcv import load_fashion_mnist, train, plot_results, plot_convolution, display_dataset\n",
    "load_fashion_mnist(batch_size=128) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional filters\n",
    "\n",
    "Convolutional filters are small windows that run over each pixel of the image and compute weighted average of the neighboring pixels.\n",
    "\n",
    "\n",
    "\n",
    "They are defined by matrices of weight coefficients. Let's see the examples of applying two different convolutional filters over our MNIST handwritten digits.\n",
    "\n",
    "The vertical edge filter emphasizes changes in intensity that occur vertically across the image, making it useful for detecting vertical lines and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolution(torch.tensor([[-1.,0.,1.],[-1.,0.,1.],[-1.,0.,1.]]),'Vertical edge filter')\n",
    "plot_convolution(torch.tensor([[-1.,-1.,-1.],[0.,0.,0.],[1.,1.,1.]]),'Horizontal edge filter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First filter is called a **vertical edge filter**, and it is defined by the following matrix:\n",
    "$$\n",
    "\\left(\n",
    "    \\begin{matrix}\n",
    "     -1 & 0 & 1 \\cr\n",
    "     -1 & 0 & 1 \\cr\n",
    "     -1 & 0 & 1 \\cr\n",
    "    \\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "When this filter goes over relatively uniform pixel field, all values add up to 0. However, when it encounters a vertical edge in the image, high spike value is generated. That's why in the images above you can see vertical edges represented by high and low values, while horizontal edges are averaged out.\n",
    "\n",
    "An opposite thing happens when we apply horizontal edge filter - horizontal lines are amplified, and vertical are averaged out.\n",
    "\n",
    "In classical computer vision, multiple filters were applied to the image to generate features, which then were used by machine learning algorithm to build a classifier. However, in deep learning we construct networks that **learn** best convolutional filters to solve classification problem.\n",
    "\n",
    "To do that, we introduce **convolutional layers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covolutional layers\n",
    "\n",
    "Convolutional layers are defined using `nn.Conv2d` construction. We need to specify the following:\n",
    "* `in_channels` - number of input channels. In our case we are dealing with a grayscale image, thus number of input channels is 1.\n",
    "* `out_channels` - number of filters to use. We will use 9 different filters, which will give the network plenty of opportunities to explore which filters work best for our scenario.\n",
    "* `kernel_size` is the size of the sliding window. Usually 3x3 or 5x5 filters are used.\n",
    "\n",
    "Simplest CNN will contain one convolutional layer. Given the input size 28x28, after applying nine 5x5 filters we will end up with a tensor of 9x24x24 (the spatial size is smaller, because there are only 24 positions where a sliding interval of length 5 can fit into 28 pixels).\n",
    "\n",
    "After convolution, we flatten 9x24x24 tensor into one vector of size 5184, and then add linear layer, to produce 10 classes. We also use `relu` activation function in between layers. \n",
    "\n",
    "The Rectified Linear Unit (ReLU) activation function is one of the most commonly used activation functions in neural networks, especially in deep learning models. The function is defined mathematically as:\n",
    "\n",
    "ReLU(x)=max(0,x)\n",
    "\n",
    "Here’s what this means:\n",
    "\n",
    "If x is greater than 0, the function returns x.\n",
    "If x is less than or equal to 0, the function returns 0.\n",
    "\n",
    "Properties of ReLU\n",
    "Non-linear: While it looks like a linear function, ReLU introduces a non-linearity (a simple threshold at 0), which allows models to learn more complex patterns.\n",
    "Computationally Efficient: It is very efficient to compute as it only requires checking if the input is positive or not.\n",
    "Sparse Activation: In practice, ReLU results in sparse activations; i.e., only a subset of neurons in a layer are active at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 불러오기\n",
    "train_data = torchvision.datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_data = torchvision.datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# 데이터셋 시각화\n",
    "def visualize_dataset(dataset):\n",
    "    classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(12, 8))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        image, label = dataset[i]\n",
    "        ax.imshow(image.squeeze(), cmap='gray')\n",
    "        ax.set_title(classes[label])\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_dataset(train_data)\n",
    "\n",
    "# 간단한 CNN 모델 정의\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 모델 생성 및 요약\n",
    "model = SimpleCNN()\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this network contains around 50k trainable parameters, compared to around 80k in fully-connected multi-layered networks. This allows us to achieve good results even on smaller datasets, because convolutional networks generalize much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 평가\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=5):\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accuracy, test_accuracy = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_train_loss / len(train_loader)\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracy.append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "        test_loss = running_test_loss / len(test_loader)\n",
    "        test_acc = 100 * correct_test / total_test\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracy.append(test_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    return train_losses, test_losses, train_accuracy, test_accuracy\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses, test_losses, train_accuracy, test_accuracy = train_model(model, train_loader, test_loader, criterion, optimizer)\n",
    "\n",
    "# 학습 과정 시각화\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accuracy, label='Train Accuracy')\n",
    "plt.plot(test_accuracy, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to achieve higher accuracy, and much faster, compared to the fully-connected networks.\n",
    "\n",
    "We can also visualize the weights of our trained convolutional layers, to try and make some more sense of what is going on:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
